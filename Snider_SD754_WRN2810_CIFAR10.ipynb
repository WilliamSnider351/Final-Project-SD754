{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SSHwgvdRiHgQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize the data (important for deep learning models)\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "-ermlWyJibCP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,  # Increased rotation range\n",
        "    width_shift_range=0.2,  # Increased width shift range\n",
        "    height_shift_range=0.2,  # Increased height shift range\n",
        "    shear_range=0.2,  # Increased shear range\n",
        "    zoom_range=0.2,  # Increased zoom range\n",
        "    horizontal_flip=True,  # Keep flipping\n",
        "    fill_mode='nearest'  # Strategy for filling in missing pixels after transformation\n",
        ")\n",
        "\n",
        "# Fit the generator on the training data\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "-NYpFFfpieDF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_wrn_model():\n",
        "    num_blocks = 3  # Number of blocks in the model\n",
        "    block_sizes = [16, 32, 64]  # Number of filters in each block\n",
        "    growth_rate = 10  # Wide ResNet scaling factor\n",
        "\n",
        "    inputs = layers.Input(shape=(32, 32, 3))\n",
        "\n",
        "    # Initial Conv Layer with padding to prevent rapid dimension reduction\n",
        "    x = layers.Conv2D(16, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Add Residual Blocks with adjusted MaxPooling layers\n",
        "    for i in range(num_blocks):\n",
        "        for _ in range(block_sizes[i] // 16):  # The number of residual blocks in each layer\n",
        "            x = layers.Conv2D(block_sizes[i], (3, 3), padding='same', activation='relu')(x)\n",
        "            x = layers.BatchNormalization()(x)\n",
        "            x = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
        "\n",
        "    # Global Average Pooling + Dense layers\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, x)\n",
        "    return model"
      ],
      "metadata": {
        "id": "BF5f6H-Xiiru"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate scheduler\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)"
      ],
      "metadata": {
        "id": "LzK_a_vIivHB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the updated model with higher learning rate\n",
        "model = build_wrn_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train with updated architecture\n",
        "model.fit(datagen.flow(x_train, y_train, batch_size=64),\n",
        "          epochs=150,  # Increased epochs\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kDnpGMajcYT",
        "outputId": "c5bbe7d1-1618-41a7-db55-825cefd05b15"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 50ms/step - accuracy: 0.3089 - loss: 1.9252 - val_accuracy: 0.4647 - val_loss: 1.5236 - learning_rate: 0.0010\n",
            "Epoch 2/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.4617 - loss: 1.4798 - val_accuracy: 0.4757 - val_loss: 1.4280 - learning_rate: 0.0010\n",
            "Epoch 3/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.5178 - loss: 1.3369 - val_accuracy: 0.5046 - val_loss: 1.3889 - learning_rate: 0.0010\n",
            "Epoch 4/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.5500 - loss: 1.2585 - val_accuracy: 0.5519 - val_loss: 1.3662 - learning_rate: 0.0010\n",
            "Epoch 5/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.5748 - loss: 1.1813 - val_accuracy: 0.6188 - val_loss: 1.0627 - learning_rate: 0.0010\n",
            "Epoch 6/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.5998 - loss: 1.1319 - val_accuracy: 0.4646 - val_loss: 1.9389 - learning_rate: 0.0010\n",
            "Epoch 7/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.6127 - loss: 1.0896 - val_accuracy: 0.6068 - val_loss: 1.1310 - learning_rate: 0.0010\n",
            "Epoch 8/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 42ms/step - accuracy: 0.6277 - loss: 1.0561 - val_accuracy: 0.6593 - val_loss: 0.9766 - learning_rate: 0.0010\n",
            "Epoch 9/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.6400 - loss: 1.0199 - val_accuracy: 0.5921 - val_loss: 1.1999 - learning_rate: 0.0010\n",
            "Epoch 10/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.6463 - loss: 0.9997 - val_accuracy: 0.6477 - val_loss: 1.0343 - learning_rate: 0.0010\n",
            "Epoch 11/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.6599 - loss: 0.9721 - val_accuracy: 0.6339 - val_loss: 1.1284 - learning_rate: 0.0010\n",
            "Epoch 12/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.6711 - loss: 0.9371 - val_accuracy: 0.6736 - val_loss: 0.9603 - learning_rate: 5.0000e-04\n",
            "Epoch 13/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.6836 - loss: 0.9026 - val_accuracy: 0.7054 - val_loss: 0.8381 - learning_rate: 5.0000e-04\n",
            "Epoch 14/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.6862 - loss: 0.8930 - val_accuracy: 0.6935 - val_loss: 0.8971 - learning_rate: 5.0000e-04\n",
            "Epoch 15/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.6882 - loss: 0.8881 - val_accuracy: 0.7106 - val_loss: 0.8389 - learning_rate: 5.0000e-04\n",
            "Epoch 16/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.6925 - loss: 0.8676 - val_accuracy: 0.6937 - val_loss: 0.8810 - learning_rate: 5.0000e-04\n",
            "Epoch 17/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.7024 - loss: 0.8461 - val_accuracy: 0.7261 - val_loss: 0.8027 - learning_rate: 2.5000e-04\n",
            "Epoch 18/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7048 - loss: 0.8391 - val_accuracy: 0.7234 - val_loss: 0.8056 - learning_rate: 2.5000e-04\n",
            "Epoch 19/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7082 - loss: 0.8364 - val_accuracy: 0.7359 - val_loss: 0.7634 - learning_rate: 2.5000e-04\n",
            "Epoch 20/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7139 - loss: 0.8244 - val_accuracy: 0.7273 - val_loss: 0.7909 - learning_rate: 2.5000e-04\n",
            "Epoch 21/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7109 - loss: 0.8257 - val_accuracy: 0.7323 - val_loss: 0.7726 - learning_rate: 2.5000e-04\n",
            "Epoch 22/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7143 - loss: 0.8193 - val_accuracy: 0.7178 - val_loss: 0.8232 - learning_rate: 2.5000e-04\n",
            "Epoch 23/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7214 - loss: 0.8052 - val_accuracy: 0.7348 - val_loss: 0.7689 - learning_rate: 1.2500e-04\n",
            "Epoch 24/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7189 - loss: 0.8040 - val_accuracy: 0.7343 - val_loss: 0.7723 - learning_rate: 1.2500e-04\n",
            "Epoch 25/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.7187 - loss: 0.8013 - val_accuracy: 0.7353 - val_loss: 0.7625 - learning_rate: 1.2500e-04\n",
            "Epoch 26/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7251 - loss: 0.7867 - val_accuracy: 0.7320 - val_loss: 0.7761 - learning_rate: 1.2500e-04\n",
            "Epoch 27/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7222 - loss: 0.7966 - val_accuracy: 0.7323 - val_loss: 0.7747 - learning_rate: 1.2500e-04\n",
            "Epoch 28/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7224 - loss: 0.7918 - val_accuracy: 0.7389 - val_loss: 0.7549 - learning_rate: 1.2500e-04\n",
            "Epoch 29/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.7233 - loss: 0.7889 - val_accuracy: 0.7455 - val_loss: 0.7405 - learning_rate: 1.2500e-04\n",
            "Epoch 30/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.7260 - loss: 0.7755 - val_accuracy: 0.7326 - val_loss: 0.7791 - learning_rate: 1.2500e-04\n",
            "Epoch 31/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7246 - loss: 0.7865 - val_accuracy: 0.7457 - val_loss: 0.7389 - learning_rate: 1.2500e-04\n",
            "Epoch 32/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.7272 - loss: 0.7773 - val_accuracy: 0.7389 - val_loss: 0.7656 - learning_rate: 1.2500e-04\n",
            "Epoch 33/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7275 - loss: 0.7817 - val_accuracy: 0.7472 - val_loss: 0.7348 - learning_rate: 1.2500e-04\n",
            "Epoch 34/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.7286 - loss: 0.7762 - val_accuracy: 0.7465 - val_loss: 0.7522 - learning_rate: 1.2500e-04\n",
            "Epoch 35/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7319 - loss: 0.7735 - val_accuracy: 0.7454 - val_loss: 0.7443 - learning_rate: 1.2500e-04\n",
            "Epoch 36/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.7314 - loss: 0.7711 - val_accuracy: 0.7519 - val_loss: 0.7219 - learning_rate: 1.2500e-04\n",
            "Epoch 37/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 42ms/step - accuracy: 0.7303 - loss: 0.7701 - val_accuracy: 0.7443 - val_loss: 0.7508 - learning_rate: 1.2500e-04\n",
            "Epoch 38/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7299 - loss: 0.7734 - val_accuracy: 0.7441 - val_loss: 0.7385 - learning_rate: 1.2500e-04\n",
            "Epoch 39/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.7281 - loss: 0.7780 - val_accuracy: 0.7474 - val_loss: 0.7375 - learning_rate: 1.2500e-04\n",
            "Epoch 40/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7341 - loss: 0.7581 - val_accuracy: 0.7500 - val_loss: 0.7253 - learning_rate: 6.2500e-05\n",
            "Epoch 41/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7345 - loss: 0.7595 - val_accuracy: 0.7439 - val_loss: 0.7473 - learning_rate: 6.2500e-05\n",
            "Epoch 42/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.7357 - loss: 0.7530 - val_accuracy: 0.7409 - val_loss: 0.7521 - learning_rate: 6.2500e-05\n",
            "Epoch 43/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7365 - loss: 0.7521 - val_accuracy: 0.7475 - val_loss: 0.7302 - learning_rate: 3.1250e-05\n",
            "Epoch 44/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.7312 - loss: 0.7656 - val_accuracy: 0.7499 - val_loss: 0.7279 - learning_rate: 3.1250e-05\n",
            "Epoch 45/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.7328 - loss: 0.7688 - val_accuracy: 0.7490 - val_loss: 0.7266 - learning_rate: 3.1250e-05\n",
            "Epoch 46/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7333 - loss: 0.7597 - val_accuracy: 0.7511 - val_loss: 0.7195 - learning_rate: 1.5625e-05\n",
            "Epoch 47/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.7385 - loss: 0.7525 - val_accuracy: 0.7504 - val_loss: 0.7217 - learning_rate: 1.5625e-05\n",
            "Epoch 48/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7372 - loss: 0.7538 - val_accuracy: 0.7508 - val_loss: 0.7205 - learning_rate: 1.5625e-05\n",
            "Epoch 49/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7358 - loss: 0.7562 - val_accuracy: 0.7524 - val_loss: 0.7178 - learning_rate: 1.5625e-05\n",
            "Epoch 50/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7356 - loss: 0.7482 - val_accuracy: 0.7524 - val_loss: 0.7211 - learning_rate: 1.5625e-05\n",
            "Epoch 51/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.7349 - loss: 0.7599 - val_accuracy: 0.7517 - val_loss: 0.7221 - learning_rate: 1.5625e-05\n",
            "Epoch 52/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.7350 - loss: 0.7570 - val_accuracy: 0.7517 - val_loss: 0.7213 - learning_rate: 1.5625e-05\n",
            "Epoch 53/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7364 - loss: 0.7556 - val_accuracy: 0.7536 - val_loss: 0.7164 - learning_rate: 1.0000e-05\n",
            "Epoch 54/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.7369 - loss: 0.7528 - val_accuracy: 0.7520 - val_loss: 0.7203 - learning_rate: 1.0000e-05\n",
            "Epoch 55/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.7387 - loss: 0.7438 - val_accuracy: 0.7519 - val_loss: 0.7182 - learning_rate: 1.0000e-05\n",
            "Epoch 56/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7353 - loss: 0.7514 - val_accuracy: 0.7512 - val_loss: 0.7220 - learning_rate: 1.0000e-05\n",
            "Epoch 57/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7365 - loss: 0.7557 - val_accuracy: 0.7531 - val_loss: 0.7195 - learning_rate: 1.0000e-05\n",
            "Epoch 58/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7418 - loss: 0.7429 - val_accuracy: 0.7536 - val_loss: 0.7160 - learning_rate: 1.0000e-05\n",
            "Epoch 59/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.7390 - loss: 0.7458 - val_accuracy: 0.7555 - val_loss: 0.7176 - learning_rate: 1.0000e-05\n",
            "Epoch 60/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 42ms/step - accuracy: 0.7358 - loss: 0.7518 - val_accuracy: 0.7570 - val_loss: 0.7116 - learning_rate: 1.0000e-05\n",
            "Epoch 61/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.7349 - loss: 0.7530 - val_accuracy: 0.7539 - val_loss: 0.7174 - learning_rate: 1.0000e-05\n",
            "Epoch 62/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.7298 - loss: 0.7674 - val_accuracy: 0.7540 - val_loss: 0.7139 - learning_rate: 1.0000e-05\n",
            "Epoch 63/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7334 - loss: 0.7538 - val_accuracy: 0.7551 - val_loss: 0.7140 - learning_rate: 1.0000e-05\n",
            "Epoch 64/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.7365 - loss: 0.7506 - val_accuracy: 0.7526 - val_loss: 0.7193 - learning_rate: 1.0000e-05\n",
            "Epoch 65/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 43ms/step - accuracy: 0.7372 - loss: 0.7509 - val_accuracy: 0.7549 - val_loss: 0.7142 - learning_rate: 1.0000e-05\n",
            "Epoch 66/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 42ms/step - accuracy: 0.7331 - loss: 0.7564 - val_accuracy: 0.7562 - val_loss: 0.7128 - learning_rate: 1.0000e-05\n",
            "Epoch 67/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.7365 - loss: 0.7508 - val_accuracy: 0.7545 - val_loss: 0.7172 - learning_rate: 1.0000e-05\n",
            "Epoch 68/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7370 - loss: 0.7467 - val_accuracy: 0.7542 - val_loss: 0.7151 - learning_rate: 1.0000e-05\n",
            "Epoch 69/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.7361 - loss: 0.7558 - val_accuracy: 0.7534 - val_loss: 0.7160 - learning_rate: 1.0000e-05\n",
            "Epoch 70/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7389 - loss: 0.7510 - val_accuracy: 0.7537 - val_loss: 0.7188 - learning_rate: 1.0000e-05\n",
            "Epoch 71/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 42ms/step - accuracy: 0.7372 - loss: 0.7482 - val_accuracy: 0.7544 - val_loss: 0.7140 - learning_rate: 1.0000e-05\n",
            "Epoch 72/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7352 - loss: 0.7544 - val_accuracy: 0.7536 - val_loss: 0.7177 - learning_rate: 1.0000e-05\n",
            "Epoch 73/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 42ms/step - accuracy: 0.7406 - loss: 0.7454 - val_accuracy: 0.7572 - val_loss: 0.7075 - learning_rate: 1.0000e-05\n",
            "Epoch 74/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.7382 - loss: 0.7523 - val_accuracy: 0.7541 - val_loss: 0.7152 - learning_rate: 1.0000e-05\n",
            "Epoch 75/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7403 - loss: 0.7415 - val_accuracy: 0.7520 - val_loss: 0.7196 - learning_rate: 1.0000e-05\n",
            "Epoch 76/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.7339 - loss: 0.7572 - val_accuracy: 0.7553 - val_loss: 0.7134 - learning_rate: 1.0000e-05\n",
            "Epoch 77/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7385 - loss: 0.7456 - val_accuracy: 0.7550 - val_loss: 0.7127 - learning_rate: 1.0000e-05\n",
            "Epoch 78/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.7388 - loss: 0.7464 - val_accuracy: 0.7549 - val_loss: 0.7152 - learning_rate: 1.0000e-05\n",
            "Epoch 79/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7370 - loss: 0.7419 - val_accuracy: 0.7552 - val_loss: 0.7111 - learning_rate: 1.0000e-05\n",
            "Epoch 80/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.7413 - loss: 0.7419 - val_accuracy: 0.7553 - val_loss: 0.7133 - learning_rate: 1.0000e-05\n",
            "Epoch 81/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.7393 - loss: 0.7446 - val_accuracy: 0.7560 - val_loss: 0.7139 - learning_rate: 1.0000e-05\n",
            "Epoch 82/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.7374 - loss: 0.7459 - val_accuracy: 0.7557 - val_loss: 0.7105 - learning_rate: 1.0000e-05\n",
            "Epoch 83/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7398 - loss: 0.7493 - val_accuracy: 0.7526 - val_loss: 0.7161 - learning_rate: 1.0000e-05\n",
            "Epoch 84/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.7409 - loss: 0.7420 - val_accuracy: 0.7547 - val_loss: 0.7117 - learning_rate: 1.0000e-05\n",
            "Epoch 85/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7384 - loss: 0.7493 - val_accuracy: 0.7550 - val_loss: 0.7138 - learning_rate: 1.0000e-05\n",
            "Epoch 86/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.7382 - loss: 0.7496 - val_accuracy: 0.7573 - val_loss: 0.7078 - learning_rate: 1.0000e-05\n",
            "Epoch 87/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7364 - loss: 0.7485 - val_accuracy: 0.7528 - val_loss: 0.7180 - learning_rate: 1.0000e-05\n",
            "Epoch 88/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.7365 - loss: 0.7519 - val_accuracy: 0.7531 - val_loss: 0.7183 - learning_rate: 1.0000e-05\n",
            "Epoch 89/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 40ms/step - accuracy: 0.7376 - loss: 0.7463 - val_accuracy: 0.7577 - val_loss: 0.7068 - learning_rate: 1.0000e-05\n",
            "Epoch 90/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.7367 - loss: 0.7470 - val_accuracy: 0.7558 - val_loss: 0.7118 - learning_rate: 1.0000e-05\n",
            "Epoch 91/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7382 - loss: 0.7445 - val_accuracy: 0.7547 - val_loss: 0.7158 - learning_rate: 1.0000e-05\n",
            "Epoch 92/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7365 - loss: 0.7496 - val_accuracy: 0.7540 - val_loss: 0.7149 - learning_rate: 1.0000e-05\n",
            "Epoch 93/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7409 - loss: 0.7424 - val_accuracy: 0.7557 - val_loss: 0.7140 - learning_rate: 1.0000e-05\n",
            "Epoch 94/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 40ms/step - accuracy: 0.7347 - loss: 0.7602 - val_accuracy: 0.7522 - val_loss: 0.7183 - learning_rate: 1.0000e-05\n",
            "Epoch 95/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7404 - loss: 0.7390 - val_accuracy: 0.7542 - val_loss: 0.7179 - learning_rate: 1.0000e-05\n",
            "Epoch 96/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7383 - loss: 0.7450 - val_accuracy: 0.7545 - val_loss: 0.7130 - learning_rate: 1.0000e-05\n",
            "Epoch 97/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7375 - loss: 0.7499 - val_accuracy: 0.7553 - val_loss: 0.7140 - learning_rate: 1.0000e-05\n",
            "Epoch 98/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7386 - loss: 0.7464 - val_accuracy: 0.7546 - val_loss: 0.7171 - learning_rate: 1.0000e-05\n",
            "Epoch 99/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7427 - loss: 0.7442 - val_accuracy: 0.7563 - val_loss: 0.7114 - learning_rate: 1.0000e-05\n",
            "Epoch 100/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7420 - loss: 0.7429 - val_accuracy: 0.7580 - val_loss: 0.7087 - learning_rate: 1.0000e-05\n",
            "Epoch 101/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7411 - loss: 0.7416 - val_accuracy: 0.7557 - val_loss: 0.7116 - learning_rate: 1.0000e-05\n",
            "Epoch 102/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7405 - loss: 0.7430 - val_accuracy: 0.7560 - val_loss: 0.7111 - learning_rate: 1.0000e-05\n",
            "Epoch 103/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7393 - loss: 0.7390 - val_accuracy: 0.7569 - val_loss: 0.7080 - learning_rate: 1.0000e-05\n",
            "Epoch 104/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.7369 - loss: 0.7498 - val_accuracy: 0.7571 - val_loss: 0.7116 - learning_rate: 1.0000e-05\n",
            "Epoch 105/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.7423 - loss: 0.7320 - val_accuracy: 0.7570 - val_loss: 0.7128 - learning_rate: 1.0000e-05\n",
            "Epoch 106/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.7375 - loss: 0.7417 - val_accuracy: 0.7567 - val_loss: 0.7090 - learning_rate: 1.0000e-05\n",
            "Epoch 107/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.7419 - loss: 0.7344 - val_accuracy: 0.7568 - val_loss: 0.7090 - learning_rate: 1.0000e-05\n",
            "Epoch 108/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7390 - loss: 0.7443 - val_accuracy: 0.7575 - val_loss: 0.7078 - learning_rate: 1.0000e-05\n",
            "Epoch 109/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.7371 - loss: 0.7470 - val_accuracy: 0.7553 - val_loss: 0.7125 - learning_rate: 1.0000e-05\n",
            "Epoch 110/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7405 - loss: 0.7451 - val_accuracy: 0.7571 - val_loss: 0.7054 - learning_rate: 1.0000e-05\n",
            "Epoch 111/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.7393 - loss: 0.7406 - val_accuracy: 0.7551 - val_loss: 0.7151 - learning_rate: 1.0000e-05\n",
            "Epoch 112/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7429 - loss: 0.7435 - val_accuracy: 0.7552 - val_loss: 0.7132 - learning_rate: 1.0000e-05\n",
            "Epoch 113/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.7417 - loss: 0.7329 - val_accuracy: 0.7550 - val_loss: 0.7163 - learning_rate: 1.0000e-05\n",
            "Epoch 114/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7397 - loss: 0.7418 - val_accuracy: 0.7558 - val_loss: 0.7127 - learning_rate: 1.0000e-05\n",
            "Epoch 115/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.7416 - loss: 0.7370 - val_accuracy: 0.7556 - val_loss: 0.7141 - learning_rate: 1.0000e-05\n",
            "Epoch 116/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7385 - loss: 0.7471 - val_accuracy: 0.7553 - val_loss: 0.7113 - learning_rate: 1.0000e-05\n",
            "Epoch 117/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 42ms/step - accuracy: 0.7400 - loss: 0.7424 - val_accuracy: 0.7515 - val_loss: 0.7192 - learning_rate: 1.0000e-05\n",
            "Epoch 118/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7384 - loss: 0.7483 - val_accuracy: 0.7559 - val_loss: 0.7072 - learning_rate: 1.0000e-05\n",
            "Epoch 119/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7358 - loss: 0.7475 - val_accuracy: 0.7558 - val_loss: 0.7109 - learning_rate: 1.0000e-05\n",
            "Epoch 120/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.7403 - loss: 0.7435 - val_accuracy: 0.7558 - val_loss: 0.7075 - learning_rate: 1.0000e-05\n",
            "Epoch 121/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7420 - loss: 0.7415 - val_accuracy: 0.7565 - val_loss: 0.7095 - learning_rate: 1.0000e-05\n",
            "Epoch 122/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.7399 - loss: 0.7395 - val_accuracy: 0.7557 - val_loss: 0.7128 - learning_rate: 1.0000e-05\n",
            "Epoch 123/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7421 - loss: 0.7392 - val_accuracy: 0.7539 - val_loss: 0.7133 - learning_rate: 1.0000e-05\n",
            "Epoch 124/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7408 - loss: 0.7407 - val_accuracy: 0.7559 - val_loss: 0.7102 - learning_rate: 1.0000e-05\n",
            "Epoch 125/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7415 - loss: 0.7413 - val_accuracy: 0.7558 - val_loss: 0.7092 - learning_rate: 1.0000e-05\n",
            "Epoch 126/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7365 - loss: 0.7482 - val_accuracy: 0.7543 - val_loss: 0.7145 - learning_rate: 1.0000e-05\n",
            "Epoch 127/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.7392 - loss: 0.7423 - val_accuracy: 0.7577 - val_loss: 0.7084 - learning_rate: 1.0000e-05\n",
            "Epoch 128/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7396 - loss: 0.7498 - val_accuracy: 0.7573 - val_loss: 0.7080 - learning_rate: 1.0000e-05\n",
            "Epoch 129/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 43ms/step - accuracy: 0.7421 - loss: 0.7365 - val_accuracy: 0.7570 - val_loss: 0.7085 - learning_rate: 1.0000e-05\n",
            "Epoch 130/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.7439 - loss: 0.7400 - val_accuracy: 0.7553 - val_loss: 0.7121 - learning_rate: 1.0000e-05\n",
            "Epoch 131/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 42ms/step - accuracy: 0.7372 - loss: 0.7437 - val_accuracy: 0.7556 - val_loss: 0.7110 - learning_rate: 1.0000e-05\n",
            "Epoch 132/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7395 - loss: 0.7454 - val_accuracy: 0.7566 - val_loss: 0.7098 - learning_rate: 1.0000e-05\n",
            "Epoch 133/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.7381 - loss: 0.7439 - val_accuracy: 0.7545 - val_loss: 0.7138 - learning_rate: 1.0000e-05\n",
            "Epoch 134/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.7410 - loss: 0.7400 - val_accuracy: 0.7566 - val_loss: 0.7101 - learning_rate: 1.0000e-05\n",
            "Epoch 135/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.7436 - loss: 0.7332 - val_accuracy: 0.7556 - val_loss: 0.7116 - learning_rate: 1.0000e-05\n",
            "Epoch 136/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 45ms/step - accuracy: 0.7385 - loss: 0.7439 - val_accuracy: 0.7574 - val_loss: 0.7090 - learning_rate: 1.0000e-05\n",
            "Epoch 137/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.7367 - loss: 0.7452 - val_accuracy: 0.7569 - val_loss: 0.7046 - learning_rate: 1.0000e-05\n",
            "Epoch 138/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.7434 - loss: 0.7329 - val_accuracy: 0.7579 - val_loss: 0.7047 - learning_rate: 1.0000e-05\n",
            "Epoch 139/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 45ms/step - accuracy: 0.7398 - loss: 0.7351 - val_accuracy: 0.7565 - val_loss: 0.7092 - learning_rate: 1.0000e-05\n",
            "Epoch 140/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.7423 - loss: 0.7407 - val_accuracy: 0.7566 - val_loss: 0.7096 - learning_rate: 1.0000e-05\n",
            "Epoch 141/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.7402 - loss: 0.7390 - val_accuracy: 0.7574 - val_loss: 0.7064 - learning_rate: 1.0000e-05\n",
            "Epoch 142/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 46ms/step - accuracy: 0.7428 - loss: 0.7351 - val_accuracy: 0.7580 - val_loss: 0.7058 - learning_rate: 1.0000e-05\n",
            "Epoch 143/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.7407 - loss: 0.7411 - val_accuracy: 0.7552 - val_loss: 0.7090 - learning_rate: 1.0000e-05\n",
            "Epoch 144/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.7431 - loss: 0.7414 - val_accuracy: 0.7564 - val_loss: 0.7122 - learning_rate: 1.0000e-05\n",
            "Epoch 145/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.7424 - loss: 0.7360 - val_accuracy: 0.7555 - val_loss: 0.7096 - learning_rate: 1.0000e-05\n",
            "Epoch 146/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 45ms/step - accuracy: 0.7402 - loss: 0.7422 - val_accuracy: 0.7596 - val_loss: 0.6981 - learning_rate: 1.0000e-05\n",
            "Epoch 147/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.7411 - loss: 0.7359 - val_accuracy: 0.7574 - val_loss: 0.7057 - learning_rate: 1.0000e-05\n",
            "Epoch 148/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 46ms/step - accuracy: 0.7397 - loss: 0.7371 - val_accuracy: 0.7565 - val_loss: 0.7087 - learning_rate: 1.0000e-05\n",
            "Epoch 149/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.7414 - loss: 0.7369 - val_accuracy: 0.7572 - val_loss: 0.7122 - learning_rate: 1.0000e-05\n",
            "Epoch 150/150\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.7436 - loss: 0.7364 - val_accuracy: 0.7583 - val_loss: 0.7037 - learning_rate: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c6286d4e790>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hr4yTEnNi5my"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}